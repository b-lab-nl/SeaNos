{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''\n",
    "We ingest the data.ods and reformat to\n",
    "client_id \\t path \\t sentence_id \\t sentence \\t locale\n",
    "\n",
    "Here\n",
    "client_id is a unique identifier for the song\n",
    "path is a path to the song\n",
    "sentence_id is a unique identifier for the sentence\n",
    "sentence is the Gaelic text\n",
    "sentence_domain=up_votes=down_votes=age=gender=accents=variant\n",
    "locale is set to ga-IE\n",
    "\n",
    "The client_id can be extracted from the filename \"song_x,..wav\"\n",
    "The sentence_id can be extracted from the \"..., phrase_xx..wav\"\n",
    "\n",
    "The filenames can be coupled to the filenames via the phrase_number, which is in on the data.ods\n",
    "'''\n"
   ],
   "id": "7b63461d10852377",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ],
   "id": "e2484a0f5dea91a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.chdir('/media/bramiozo/DATA-FAST/TTS/tts_models/gle/seannos_datasource')",
   "id": "f897864e2adefed1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lyrics_original =  pd.read_excel('dataset_lyrics/lyrics.ods')",
   "id": "5c6e2d153be528f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lyrics_original.dtypes",
   "id": "2d3dd7398cbd91d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hashlib.md5(b\"bladiebla\").hexdigest()",
   "id": "2eea17e322ef9ee3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_song_str(fn):\n",
    "    part_1 = (fn.split(',')[0]).strip()\n",
    "    part_2 = part_1.split(\"_\")[-2:]\n",
    "    return \"_\".join(part_2)"
   ],
   "id": "819cf68f4682ad86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filenames = os.listdir('clips')\n",
    "\n",
    "file_df = pd.DataFrame([{'client_id': hashlib.md5(b\"\"+(f\"{get_song_str(s)}\").encode(\"latin1\")).hexdigest(),\n",
    "  'path': s,\n",
    "  'song': s.split(\",\")[0].strip().split(\"_\")[-1],\n",
    "  'phrase_version': s.split(\"_\")[0],\n",
    "  'phrase_number': int(s.split(',')[1].strip().split(\"_\")[1])\n",
    "  } for s in filenames])"
   ],
   "id": "c38f20cb39ac9220",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "file_df",
   "id": "5fca883a9bdcbf8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_df = lyrics_original[['phrase_number', 'sentence']].merge(file_df, how='inner', on='phrase_number')",
   "id": "4fd8f1d71999b637",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_df = final_df.assign(locale='ga-IE')\n",
    "final_df = final_df.assign(sentence_domain='')\n",
    "final_df = final_df.assign(up_votes='')\n",
    "final_df = final_df.assign(down_votes='')\n",
    "final_df = final_df.assign(age='')\n",
    "final_df = final_df.assign(gender='')\n",
    "final_df = final_df.assign(accents='')\n",
    "final_df = final_df.assign(variant='')"
   ],
   "id": "58ea882dcab884",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gender_map = {\n",
    "    '1': 'male',\n",
    "    '2': 'female',\n",
    "    '3': 'female',\n",
    "    '4': 'male',\n",
    "    '5': 'female',\n",
    "    '6': 'female', \n",
    "    '7': 'male',\n",
    "    '8': 'male',\n",
    "    '9': 'male',\n",
    "    '11': 'female',\n",
    "    '12': 'female',\n",
    "    '13': 'female',\n",
    "    '14': 'female',\n",
    "    '15': 'male',\n",
    "    '16': 'male',\n",
    "    '17': 'female',\n",
    "    '18': 'male',\n",
    "    '19': 'male',\n",
    "    '22': 'female',\n",
    "    '23': 'female',\n",
    "    '24': 'female',\n",
    "    '25': 'female',\n",
    "    '26': 'female',\n",
    "    '27': 'female',\n",
    "    '28': 'female',\n",
    "    '29': 'female',\n",
    "    '30': 'male',\n",
    "    '31': 'female',\n",
    "    '32': 'female', \n",
    "    '33': 'female',\n",
    "    '34': 'female',\n",
    "    '35': 'female',\n",
    "    '36': 'female',\n",
    "    '37': 'female',\n",
    "    '38': 'male',\n",
    "    '39': 'female',   \n",
    "}\n",
    "\n",
    "client_map = {\n",
    "    'fb10b1b655a2b34af288a4ff51460080': 'female',\n",
    "    'eb6e87c69c6bb1914b33b66e22c43b22': 'female',\n",
    "    'ce29c518eaf3469a00c1b49df4a6fa58': 'female',\n",
    "    'b9ce569cc8664a79633c2e49b6951772': 'female',\n",
    "    'b501dd4c046f528a66c085a29a77fa96': 'female',\n",
    "    'ad7c36b78f0904b97958275bc316fc4a': 'female',\n",
    "    'a168b2952fd26fad6352725ad5d32c89': 'male',\n",
    "    'a05faf2da14346a9eebcb1cef52cdf70': 'male',\n",
    "    '9d6bf453b18c2401cf42e86fd7084048': 'male',\n",
    "    '9be4875162b0b52ac5853090d9816d9e': 'female',\n",
    "    '8a3d80b09d305f7e61710569dacd7b8a': 'male',\n",
    "    '82072466fe7e953258121bfed776c4c8': 'male',\n",
    "    '8059835b0296b8f2d8f88ee9d5ff2bc1': 'female',\n",
    "    '7cc5fa83c13a9bba0058047168213fd3': 'female',\n",
    "    '7396e94dda5897f01e213ea8895f5f34': 'female',\n",
    "    '6685ae01c52fccb1b73d803bc0ac65f2': 'female',\n",
    "    '5d179b5ee524d198cb483c6b6ff22e56': 'female',\n",
    "    '5641ceb7957ec589f136638189c5fc5d': 'male',\n",
    "    '53deaae6c3c39e7db142a88fb1859ba8': 'female',\n",
    "    '5200d298dcdf65f11f9b738a8b0b68dd': 'male',\n",
    "    '42a114cfae45f0e7562ecee67c7c4b9b': 'female',\n",
    "    '40b30d9f3e6d06f3d9cc6d118b04fda7': 'male',\n",
    "    '3f4d025bf63ba0bd11873d448217c394': 'female',\n",
    "    '3c514de0167d3e12cda5f1221269ccfa': 'male',\n",
    "    '3b1b99b2d042b9228b9b6ed7ba6ef0cf': 'female',\n",
    "    '2d6587eaf934b300a40091b3df85ce66': 'female',\n",
    "    '2bfd305a6c139c602fcf11065c368d67': 'male',\n",
    "    '23f2d50b628d98ecd1458b53ebd1e0c4': 'male',\n",
    "    '24b00678a1add71b1a69837a0e2478c1': 'female',\n",
    "    '5599a98ac42fb2d3b2618ca52d4ee48c': 'female',\n",
    "    'e687cfb58aa0a2abf7dc596503cfcf68': 'female',\n",
    "    '666ac977145186527ee2ee11e0b8335e': 'female',\n",
    "    '40291794d294568b8e881d84b63b4d4a': 'female',\n",
    "    '717a92c1cd9b05391b5e20b6ddb6e98e': 'female',\n",
    "    '03c0170448334d0b0cfab68ee3690b7c': 'male',\n",
    "    'e30aaf33d6b93dc7b766641a2a03efc1': 'female'\n",
    "}\n"
   ],
   "id": "ea7fd35e023e7534",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_df = final_df.assign(gender=final_df.song.map(gender_map))\n",
    "#final_df = final_df.assign(client_id=final_df.client_id.map(client_map))"
   ],
   "id": "91c91867d279edc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_df = final_df.dropna(subset=['sentence'], axis=0)",
   "id": "4e1ab175f378a13a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_df = final_df.assign(sentence_id = final_df.sentence.apply(lambda s: hashlib.md5(s.encode(\"utf-8\")).hexdigest() ))",
   "id": "f94eabcaf085bb39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_df.sentence = final_df.sentence.str.replace('*','', regex=False)\n",
    "final_df.sentence = final_df.sentence.str.replace('-',', ', regex=False)\n",
    "final_df.sentence = final_df.sentence.str.replace('–',', ', regex=False)\n",
    "final_df.sentence = final_df.sentence.str.replace('`',\"'\", regex=False)\n",
    "final_df.sentence = final_df.sentence.str.replace('’',\"'\", regex=False)\n",
    "final_df.sentence = final_df.sentence.str.replace('‘',\"'\", regex=False)"
   ],
   "id": "c1aa2141d69f17d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_df",
   "id": "d8e16a9e138d6ec7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:40:42.319686Z",
     "start_time": "2024-09-16T21:40:42.253811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import unicodedata\n",
    "\n",
    "phoneme_mapping = {\n",
    "    # Map dental stops to alveolar stops\n",
    "    't̪': 't',\n",
    "    'd̪': 'd',\n",
    "    # Map nasal variations to 'n'\n",
    "    'n̠': 'n',\n",
    "    # Map lateral variations\n",
    "    'l̠': 'l',\n",
    "    # Add other mappings as needed\n",
    "}\n",
    "\n",
    "def clean_phonemes(phonemes):\n",
    "    # Remove stress markers and punctuation\n",
    "    phonemes = phonemes.replace('ˈ', '').replace('ˌ', '')\n",
    "    phonemes = phonemes.replace('.', '').replace('|', '')\n",
    "    phonemes = phonemes.replace('?', '').replace('!', '').replace(',', '').replace(';', '')\n",
    "    # Normalize Unicode to decompose characters\n",
    "    phonemes = unicodedata.normalize('NFD', phonemes)\n",
    "    # Remove diacritic marks (characters with combining class 'Mn')\n",
    "    phonemes = ''.join([c for c in phonemes if unicodedata.category(c) != 'Mn'])\n",
    "    # Split phonemes and apply mapping\n",
    "    phoneme_list = phonemes.strip().split(' ')\n",
    "    mapped_phonemes = [phoneme_mapping.get(p, p) for p in phoneme_list]\n",
    "    # Remove empty strings\n",
    "    mapped_phonemes = [p for p in mapped_phonemes if p]\n",
    "    # Rejoin phonemes\n",
    "    phonemes = ' '.join(mapped_phonemes)\n",
    "    return phonemes"
   ],
   "id": "d9b2ab618998599e",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:41:24.254443Z",
     "start_time": "2024-09-16T21:40:42.587285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from TTS.tts.utils.text.phonemizers import ESpeak\n",
    "\n",
    "phonemizer = ESpeak(language='ga')\n",
    "phoneme_set = set()\n",
    "\n",
    "# Replace this with the path to your dataset's text file\n",
    "\n",
    "sentence_list = final_df.sentence.unique()\n",
    "for line in tqdm(sentence_list):\n",
    "    text = line.strip()\n",
    "    phonemes = phonemizer.phonemize(text, separator=\" \")\n",
    "    phonemes = clean_phonemes(phonemes)\n",
    "    phoneme_set.update(phonemes.split())"
   ],
   "id": "5afe336667976cb2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 692/692 [00:41<00:00, 16.66it/s]\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:41:24.409284Z",
     "start_time": "2024-09-16T21:41:24.365232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the phoneme list\n",
    "phoneme_list = sorted(phoneme_set)\n",
    "print(len(phoneme_list))"
   ],
   "id": "156027622365e4e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:41:24.641045Z",
     "start_time": "2024-09-16T21:41:24.575912Z"
    }
   },
   "cell_type": "code",
   "source": "print(\" \".join(phoneme_list))",
   "id": "c039b74c9b71f189",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"hʲ A a aɪ aʊ b bʲ c cʲ d dʒ dʲ e eɪ eː f fʲ h hʲ i iə iː j k kʲ l ln lɪ lʲ m mʲ n nʲ oː p pʲ r s t tʃ tʲ u uə uː v vʲ w x z ŋ ŋʲ ɐ ɑː ɒ ɔ ə ə\" ət ɛ ɡ ɡʲ ɣ ɪ ɹ ʁ ʃ ʊ ʌ ʒ ʲ χ\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns = ['client_id', 'path', 'sentence', 'sentence_id', 'sentence_domain', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale']\n",
    "\n",
    "# from client_id select 2 sentences for validation and remove from final_df\n",
    "test_df = final_df.groupby('client_id').apply(lambda x: x.sample(n=2, replace=False)).drop('client_id', axis=1).reset_index()\n",
    "rm_indcs = test_df.level_1\n",
    "test_df = test_df.drop('level_1', axis=1)"
   ],
   "id": "19699cd563387673",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mask = np.ones(len(final_df), dtype=bool)\n",
    "mask[rm_indcs] = False\n",
    "train_df = final_df.iloc[mask]"
   ],
   "id": "ade6f4d64f752a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import wave\n",
    "def get_wav_duration(filepath):\n",
    "    with wave.open(filepath, 'rb') as wav_file:\n",
    "        frames = wav_file.getnframes()\n",
    "        rate = wav_file.getframerate()\n",
    "        duration = frames / float(rate)\n",
    "        return int(duration * 1000)  "
   ],
   "id": "ebf5ba359be2dd6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "duration_df = []\n",
    "for f in filenames:\n",
    "    duration = get_wav_duration(os.path.join('clips_processed', f))\n",
    "    duration_df.append({'clip': f,  'duration[ms': duration})\n",
    "    \n",
    "pd.DataFrame(duration_df).to_csv('clip_durations.tsv', sep='\\t', index=False)\n",
    "\n"
   ],
   "id": "6d6195743d74a2fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dur_df = pd.DataFrame(duration_df)",
   "id": "5477eaec9e63f4d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dur_df[dur_df['duration[ms']>15_000]['clip'].str.split(\",\").apply(lambda x: x[1]).nunique()",
   "id": "64f5dea214a84be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "keep_phrases = dur_df[dur_df['duration[ms']<15_000]['clip'].values",
   "id": "d476221a7cbd009e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_df = train_df.loc[train_df.path.isin(keep_phrases)]\n",
    "test_df = test_df.loc[test_df.path.isin(keep_phrases)]\n"
   ],
   "id": "fa8b745ee6c42f34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df[columns].to_csv('test.tsv', sep='\\t', index=False)\n",
    "train_df[columns].to_csv('train.tsv', sep='\\t', index=False)"
   ],
   "id": "e5c324062ba30af2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "990a34d5e67960f7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
