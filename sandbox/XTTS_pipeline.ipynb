{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# add autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from TTS.api import TTS # only in v0.22\n",
    "from TTS.tts.models.vits import Vits\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "\n",
    "from TTS.tts.utils.synthesis import synthesis\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "\n",
    "\n",
    "from neon_tts_plugin_coqui import CoquiTTS as neonTTS\n",
    "from IPython.display import Audio\n",
    "from neon_tts_plugin_coqui.configs import tts_config\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import welch\n",
    "from scipy.signal import iirnotch, filtfilt, sosfiltfilt, butter, sosfilt, sosfreqz\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.ops.gen_logging_ops import audio_summary\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "import noisereduce as nr\n",
    "from src import preprocessing\n",
    "\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "from pydub import AudioSegment"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_and_save_melspec(mel_spectrogram, sampling_rate, output_path=\"../artifacts/melgram.png\"):\n",
    "    # Generate mel spectrogram\n",
    "    print(f\"Mel spectrogram shape: {mel_spectrogram.shape}\")\n",
    "    print(f\"Sampling rate: {sampling_rate}\")\n",
    "\n",
    "    # Save mel spectrogram as numpy array\n",
    "    np.save(output_path + \".npy\", mel_spectrogram)\n",
    "    print(f\"Mel spectrogram saved to {output_path}.npy\")\n",
    "\n",
    "    # Optionally, visualize and save the mel spectrogram as an image\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(mel_spectrogram, aspect='auto', origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path + \".png\")\n",
    "    print(f\"Mel spectrogram visualization saved to {output_path}.png\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Vocoder test"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def apply_vocoder(synthesizer, mel_spectrogram, output_path=\"../artifacts/vocoder.wav\"):\n",
    "    # Convert to tensor if it's not already\n",
    "    if not isinstance(mel_spectrogram, torch.Tensor):\n",
    "        mel_spectrogram = torch.FloatTensor(mel_spectrogram)\n",
    "\n",
    "    # Ensure mel_spectrogram is the right shape (add batch dimension if needed)\n",
    "    if mel_spectrogram.dim() == 2:\n",
    "        mel_spectrogram = mel_spectrogram.unsqueeze(0)\n",
    "\n",
    "    # Move to the same device as the vocoder (CUDA in this case)\n",
    "    mel_spectrogram = mel_spectrogram.cuda()\n",
    "\n",
    "    # Generate waveform\n",
    "    with torch.no_grad():\n",
    "        waveform = synthesizer.vocoder_model(mel_spectrogram)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    waveform = waveform.cpu().numpy().squeeze()\n",
    "\n",
    "    # Normalize audio to [-1, 1] range\n",
    "    waveform = waveform / np.max(np.abs(waveform))\n",
    "\n",
    "    # Get the sampling rate from the synthesizer\n",
    "    sample_rate = synthesizer.vocoder_model.config.audio.sample_rate\n",
    "    if sample_rate is None:\n",
    "        # Fallback to a common sample rate if not found in config\n",
    "        sample_rate = 22050\n",
    "        print(f\"Warning: Sample rate not found in vocoder config. Using default: {sample_rate}\")\n",
    "\n",
    "\n",
    "    # Save as wav file\n",
    "    sf.write(output_path, waveform, sample_rate)\n",
    "    print(f\"Audio saved to {output_path}\")\n",
    "\n",
    "    return waveform, sample_rate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from TTS.utils.synthesizer import Synthesizer",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# try https://huggingface.co/nvidia/tts_hifigan",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "vocoder_path = \"/media/bramiozo/DATA-FAST/TTS/tts_models/gle/hifigan_vocoder_seanos\"",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "synthesizer = Synthesizer()\n",
    "synthesizer._load_vocoder(model_file=os.path.join(vocoder_path, \"model_file.pth.tar\"), \n",
    "                          model_config=os.path.join(vocoder_path, \"config.json\"), \n",
    "                          use_cuda=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tts_path = \"/media/bramiozo/DATA-FAST/TTS/tts_models/gle/tts-vits-cv-ga_seanos\"\n",
    "tts_model = TTS(progress_bar=True,\n",
    "                model_path=os.path.join(tts_path, \"withPhonemes_withSpeakerEncoder_fft4098_allSingers_seperatedByPrep/model_file.pth.tar\"),\n",
    "                config_path=os.path.join(tts_path, \"withPhonemes_withSpeakerEncoder_fft4098_allSingers_seperatedByPrep/config.json\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tts_synthesizer = Synthesizer(tts_checkpoint=os.path.join(tts_path, \"withPhonemes_withSpeakerEncoder_fft4098_allSingers_seperatedByPrep/model.pth\"),\n",
    "                              tts_config_path=os.path.join(tts_path, \"withPhonemes_withSpeakerEncoder_fft4098_allSingers_seperatedByPrep/config.json\"),\n",
    "                              tts_speakers_file=os.path.join(tts_path, \"withPhonemes_withSpeakerEncoder_fft4098_allSingers_seperatedByPrep/speakers.pth\"),\n",
    "                              tts_languages_file=os.path.join(tts_path, \"language_ids.pth\"),\n",
    "                              vocoder_config=os.path.join(vocoder_path, \"config.json\"),\n",
    "                              vocoder_checkpoint=os.path.join(vocoder_path, \"best_model.pth\")\n",
    "                              )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_neonTTS = neonTTS(lang=\"ga\", config={})",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "irish_lyrics = \"\"\"\n",
    "Bhí loch ag mo sheanmháthair,\n",
    "Áit ina raibh na lachain ag snámh,\n",
    "Le héadain bhána geal,\n",
    "Is cluimhreach chomh bog le scamall.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Ó, a lachain álainn, a sheod,\n",
    "Le do ghlór binn i gconaí ag glaoch,\n",
    "I do loch ghlé geal,\n",
    "Agus tú chomh saor le gaoth.\n",
    "\n",
    "Sa mhaidin chiúin go moch,\n",
    "Bhí an lacha ag éirí as a suan,from scipy.signal import welch\n",
    "\n",
    "Le heireabaill ag crith,    output_path = raw_audio_file.replace('.wav', '_int16.wav')\n",
    "    sample_rate, data = wavfile.read(raw_audio_file)\n",
    "Is a sciatháin ag sracadh an uisce.\n",
    "\n",
    "Ó, a lachain álainn, a sheod,\n",
    "Le do ghlór binn i gconaí ag glaoch,\n",
    "I do loch ghlé geal,\n",
    "Agus tú chomh saor le gaoth.\n",
    "\n",
    "Nuair a tháinig an tráthnóna,\n",
    "Bhí na lachain fós ann,\n",
    "Le spraoi is súgradh leo,\n",
    "Agus an ghrian ag dul faoi chiúin.\n",
    "\n",
    "Ó, a lachain álainn, a sheod,\n",
    "Le do ghlór binn i gconaí ag glaoch,\n",
    "I do loch ghlé geal,\n",
    "Agus tú chomh saor le gaoth.\n",
    "\n",
    "Anois tá cuimhne agam ort,\n",
    "A lachain mo sheanmháthar,\n",
    "Áit álainn ar domhan,\n",
    "Nach n-imeoidh uaim go bráth.\n",
    "\n",
    "Ó, a lachain álainn, a sheod,\n",
    "Le do ghlór binn i gconaí ag glaoch,\n",
    "I do loch ghlé geal,\n",
    "Agus tú chomh saor le gaoth\n",
    "\"\"\"\n",
    "\n",
    "dutch_lyrics = \"\"\"\n",
    "Zooals ik eenmaal beminde,\n",
    "Zoo minde er op aarde nooit een,\n",
    "Maar 'k vond, tot wien ik mij wendde,\n",
    "Slechts harten van ijs en van steen.\n",
    "\n",
    "Toen stierf mijn geloof aan de vriendschap,\n",
    "Mijn hoop en mijn liefde verdween,\n",
    "En zooals mijn hart toen haatte,\n",
    "Zoo haatte er op aarde nooit een.\n",
    "\n",
    "En sombere, bittere liederen\n",
    "Zijn aan mijn lippen ontgleên;\n",
    "Zoo somber en bitter als ik zong,\n",
    "Zoo zong er op aarde nooit een.\n",
    "\n",
    "Verveeld heeft mij eindlijk dat haten,\n",
    "Dat eeuwig gezang en geween,\n",
    "Ik zweeg, en zooals ik nu zwijg,\n",
    "Zoo zweeg er op aarde nooit een.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tts_model.speakers",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "good_speakers = [ 'MCV_e4da3b7fbbce2345d7772b0674a318d5',\n",
    "                  'MCV_d3d9446802a44259755d38e6d163e820',\n",
    "                ]\n",
    "                  # 'MCV_3c59dc048e8850243be8079a5c74d079',\n",
    "                  # 'MCV_8e296a067a37563370ded05f5a3bf3ec',\n",
    "                  # 'MCV_4e732ced3463d06de0ca9a15b6153677', \n",
    "                  # 'MCV_fbb1a0cf39f11efcc031d950dabb052e', \n",
    "                  # 'MCV_f289a00eda27794bd63b377387375254',\n",
    "                  # 'MCV_e44c6be17899cf79fdc1997268b5366d',\n",
    "                  # 'MCV_fbb1a0cf39f11efcc031d950dabb052e', \n",
    "                  # 'MCV_8f14e45fceea167a5a36dedd4bea2543'\n",
    "                  \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T09:41:26.999385Z",
     "start_time": "2024-11-08T09:41:26.870464Z"
    }
   },
   "cell_type": "code",
   "source": "len(tts_model.speakers), [s in tts_model.speakers for s in good_speakers]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, [True, True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:34:49.117364Z",
     "start_time": "2024-11-08T10:34:42.640663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# randomly select from speaker list \n",
    "synth = tts_model.synthesizer\n",
    "sampling_rate = synth.output_sample_rate\n",
    "files_written = []\n",
    "waveforms = []\n",
    "for speaker_id in good_speakers:    \n",
    "    irish_waveform = synth.tts(irish_lyrics, speaker_name=speaker_id)\n",
    "    irish_waveform = np.array(irish_waveform)\n",
    "    irish_waveform = np.squeeze(irish_waveform)\n",
    "    \n",
    "    # Normalize and convert to 16-bit PCM\n",
    "    data_int16 = np.int16(irish_waveform * 32767)  # Scale floats to 16-bit integer range        \n",
    "    # Save the converted data as a new .wav file           \n",
    "    fwrite = f\"../artifacts/RAW_irish_finetuned_speaker{speaker_id}.wav\"\n",
    "    wavfile.write(fwrite, rate=sampling_rate, data=data_int16)\n",
    "    waveforms.append(data_int16)\n",
    "    files_written.append(fwrite)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Bhí loch ag mo sheanmháthair,', 'Áit ina raibh na lachain ag snámh,', 'Le héadain bhána geal,', 'Is cluimhreach chomh bog le scamall.']\n",
      " > Processing time: 2.638947010040283\n",
      " > Real-time factor: 0.2142065524921525\n",
      " > Text splitted to sentences.\n",
      "['Bhí loch ag mo sheanmháthair,', 'Áit ina raibh na lachain ag snámh,', 'Le héadain bhána geal,', 'Is cluimhreach chomh bog le scamall.']\n",
      " > Processing time: 3.476327657699585\n",
      " > Real-time factor: 0.2150854832211206\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:00:42.529489Z",
     "start_time": "2024-11-08T10:00:42.367783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load in 10 random reference waveforms\n",
    "base_dir = '/media/bramiozo/DATA-FAST/TTS/tts_models/gle/seannos_datasource/clips'\n",
    "ref_wav_files = os.listdir(base_dir)\n",
    "reference_waves = []\n",
    "for ref_wav_file in random.choices(ref_wav_files, k=40):\n",
    "    rate, data = wavfile.read(os.path.join(base_dir, ref_wav_file))\n",
    "    reference_waves.append((rate, data))"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:39:46.674783Z",
     "start_time": "2024-11-08T10:39:46.156252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_fft = 2048\n",
    "win_length = 2048\n",
    "hop_length = 1024\n",
    "\n",
    "for raw_audio_file in files_written:\n",
    "    rate, data = wavfile.read(raw_audio_file)\n",
    "    reduced_noise = nr.reduce_noise(y=data, sr=rate, prop_decrease=0.8, n_fft=n_fft, win_length=win_length, hop_length=hop_length)\n",
    "    raw_audio_file_denoised = raw_audio_file.replace('.wav', '_denoised.wav')    \n",
    "    wavfile.write(raw_audio_file_denoised, rate, reduced_noise)\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T09:46:51.816275Z",
     "start_time": "2024-11-08T09:46:51.608412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "use_mono = False\n",
    "use_noise_reduction = True\n",
    "use_high_pass = True\n",
    "use_low_pass = True\n",
    "use_autotrim = False\n",
    "use_pitcher = False\n",
    "use_resampler = False\n",
    "use_noise_adder = False\n",
    "use_kernel_smoother = True\n",
    "use_special_smoother = True\n",
    "kwargs = {\n",
    "    'noise_freq': 128,\n",
    "    'octave_change': 0.25,\n",
    "    'target_sample_rate': 44_000,\n",
    "    'noise_level': 1e-4,\n",
    "    'smoothing_kernel': (1,1,1),\n",
    "    'window_length': 33,\n",
    "    'poly_order': 3,\n",
    "    'kernel_type': 'savgol_filter' # \n",
    "}\n",
    "\n",
    "for raw_audio_file in files_written:\n",
    "    output_path = raw_audio_file.replace('.wav', '_postprocessed.wav')\n",
    "    audio_segment = AudioSegment.from_wav(raw_audio_file)\n",
    "    processed_audio = preprocessing.process_audio(audio_segment,\n",
    "                                    use_noise_reduction,\n",
    "                                    use_high_pass,\n",
    "                                    use_low_pass,\n",
    "                                    use_autotrim,\n",
    "                                    use_pitcher,\n",
    "                                    use_mono,\n",
    "                                    use_resampler,\n",
    "                                    use_noise_adder,\n",
    "                                    use_kernel_smoother,\n",
    "                                    use_special_smoother,\n",
    "                                    **kwargs\n",
    "                                    )\n",
    "    processed_audio.export(output_path, format=\"wav\")\n",
    "    print(f\"Saved processed audio to {output_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed audio to ../artifacts/RAW_irish_finetuned_speakerMCV_e4da3b7fbbce2345d7772b0674a318d5_postprocessed.wav\n",
      "Saved processed audio to ../artifacts/RAW_irish_finetuned_speakerMCV_d3d9446802a44259755d38e6d163e820_postprocessed.wav\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T09:47:48.159591Z",
     "start_time": "2024-11-08T09:47:26.349030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for raw_audio_file in files_written:\n",
    "    rate, data = wavfile.read(raw_audio_file)\n",
    "    frequencies, psd = welch(data, fs=rate, nperseg=1024)   \n",
    "    plt.semilogy(frequencies, psd)\n",
    "    plt.title('Power Spectral Density (PSD), synthetic material')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('Power/Frequency [dB/Hz]')\n",
    "    plt.grid()\n",
    "    plt.xlim(0,20_000)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T10:01:12.042137Z",
     "start_time": "2024-11-08T10:00:59.826540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for sr, waveform in reference_waves:\n",
    "    frequencies, psd = welch(waveform, fs=44_000, nperseg=1024)   \n",
    "    plt.semilogy(frequencies, psd)\n",
    "    plt.title('Power Spectral Density (PSD), source material')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('Power/Frequency [dB/Hz]')\n",
    "    plt.grid()\n",
    "    plt.xlim(0,20_000)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T09:48:41.236702Z",
     "start_time": "2024-11-08T09:48:41.106751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def repeated_filtering(data, \n",
    "                       filter_freqs=[2330, 2750, 3350, 4350], \n",
    "                       Qs=[50,50,70,70],\n",
    "                       fs=44_000):\n",
    "    assert(len(filter_freqs) == len(Qs)), \"You need as many Qs as Freqs\"\n",
    "    \n",
    "    filtered_wav = data.copy()\n",
    "    for freq,Q in zip(filter_freqs,Qs):\n",
    "        b,a = iirnotch(freq, Q, fs)\n",
    "        filtered_wav = filtfilt(b, a, filtered_wav)\n",
    "    return filtered_wav\n",
    "\n",
    "def repeated_filtering_sos(data, \n",
    "                       filter_freqs=[2330, 2750, 3350, 4350], \n",
    "                       Rs=[50, 50, 50, 50],\n",
    "                       order=4,\n",
    "                       fs=44_000):\n",
    "    assert(len(filter_freqs) == len(Rs)), \"You need as many Qs as Freqs\"\n",
    "    \n",
    "    filtered_wav = data.copy()\n",
    "    for freq,R in zip(filter_freqs,Rs):\n",
    "        f_low, f_high = freq-R, freq+R \n",
    "        sos = butter(order, [f_low, f_high], btype='bandstop', fs=fs, output='sos')\n",
    "        filtered_wav = sosfilt(sos, filtered_wav)\n",
    "    return filtered_wav"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T09:48:52.552429Z",
     "start_time": "2024-11-08T09:48:45.830462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kwargs = {\n",
    "    'filter_freqs' :[2350],# , 2750, 3120, 4340],\n",
    "    'Qs' : [120], #,80,100,100],\n",
    "    'fs' : 44_000\n",
    "}\n",
    "plt.figure(figsize=(10, 6))\n",
    "for raw_audio_file in files_written:\n",
    "    rate, data = wavfile.read(raw_audio_file)\n",
    "    filtered_waveform = repeated_filtering(data, **kwargs)\n",
    "    \n",
    "    raw_audio_file_denoised = raw_audio_file.replace('.wav', '_denoised_notch.wav')    \n",
    "    wavfile.write(raw_audio_file_denoised, rate, filtered_waveform)\n",
    "\n",
    "    frequencies, psd = welch(filtered_waveform, fs=rate, nperseg=1024)  \n",
    "    plt.semilogy(frequencies, psd)\n",
    "    plt.title('Power Spectral Density (PSD)')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('Power/Frequency [dB/Hz]')\n",
    "    plt.grid()\n",
    "    plt.xlim(0,20_000)\n",
    "plt.axhline(y=480, color='k')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T09:48:58.998863Z",
     "start_time": "2024-11-08T09:48:55.948376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kwargs = {\n",
    "    'filter_freqs' :[2350, 2750, 3120, 4340],\n",
    "    'Rs' : [50,50,50,50],\n",
    "    'fs' : 44_000,\n",
    "    'order': 4\n",
    "}\n",
    "plt.figure(figsize=(10, 6))\n",
    "for raw_audio_file in files_written:\n",
    "    rate, data = wavfile.read(raw_audio_file)\n",
    "    filtered_waveform = repeated_filtering_sos(data, **kwargs)\n",
    "    frequencies, psd = welch(filtered_waveform, fs=rate, nperseg=1024)   \n",
    "    \n",
    "    raw_audio_file_denoised = raw_audio_file.replace('.wav', '_denoised_butter.wav')    \n",
    "    wavfile.write(raw_audio_file_denoised, rate, filtered_waveform)\n",
    "    \n",
    "    plt.semilogy(frequencies, psd)\n",
    "    plt.title('Power Spectral Density (PSD)')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('Power/Frequency [dB/Hz]')\n",
    "    plt.grid()\n",
    "    plt.xlim(0,20_000)\n",
    "    \n",
    "plt.axhline(y=480, color='k')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
